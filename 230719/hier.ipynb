{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cici_test_dir='/home/irteam/junghye-dcloud-dir/MLAC/230624/CICI'\n",
    "X_test=pd.read_csv(os.path.join(cici_test_dir,'X_test.csv'))\n",
    "y_test=pd.read_csv(os.path.join(cici_test_dir,'y_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.DataFrame(columns=['L1_acc','L1_f1','L1_rc','L1_pc','L2_acc','L2_f1','L2_rc','L2_pc']+\\\n",
    "                 ['c1_acc','c1_f1','c1_rc','c1_pc']+\\\n",
    "                    ['c2_acc','c2_f1','c2_rc','c2_pc','c3_acc','c3_f1','c3_rc','c3_pc','c4_acc','c4_f1','c4_rc','c4_pc']+\\\n",
    "                     ['total_acc','total_f1','total_rc','total_pc'])\n",
    "\n",
    "cnt=0\n",
    "model_eval=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L1_ytest=y_test.copy()\n",
    "\n",
    "L2_ytest=X_test['nist_category'].copy()\n",
    "\n",
    "L3_ytest=X_test['attack_category'].copy()\n",
    "\n",
    "c1_Xtest=X_test.query('nist_category==1')\n",
    "c1_ytest=c1_Xtest['attack_category']\n",
    "\n",
    "c2_Xtest=X_test.query('nist_category==2')\n",
    "c2_ytest=c2_Xtest['attack_category']\n",
    "\n",
    "c3_Xtest=X_test.query('nist_category==3')\n",
    "c3_ytest=c3_Xtest['attack_category']\n",
    "\n",
    "c4_Xtest=X_test.query('nist_category==4')\n",
    "c4_ytest=c4_Xtest['attack_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_data in [c1_Xtest,c2_Xtest,c3_Xtest,c4_Xtest]:\n",
    "    class_data.drop(labels=['attack_category','nist_category'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(labels=['Unnamed: 0','nist_category','attack_category'],axis=1,inplace=True)\n",
    "L1_ytest.drop(labels=['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(model:str,test,pred) ->list:\n",
    "\n",
    "    acc=accuracy_score(test,pred)\n",
    "    f1=f1_score(test,pred,average='weighted')\n",
    "    recall=recall_score(test,pred,average='weighted')\n",
    "    precision=precision_score(test,pred,average='weighted')\n",
    "\n",
    "    result=[acc,f1,recall,precision]\n",
    "    result=[round(num,3) for num in result]\n",
    "\n",
    "    print(f'{model} result , acc:{result[0]}, f1:{result[1]},recall:{result[2]},precision:{result[3]}')\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path='/home/irteam/dcloud-global-dir/MLAC/saved_models/230620/savedmodels'\n",
    "confusion_path='/home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/confusion'\n",
    "\n",
    "out_txt_path='/home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/L1_Output.txt'\n",
    "out_csv_path='/home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/ver1.csv'\n",
    "progressLog_path='/home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/L1_progressLog.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L1_model=joblib.load(os.path.join(saved_path,'CICI_L1mod_rc.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 test starts...\n",
      "result is acc, recall, time\n",
      "Batch: 1, 0.992, 0.992\n",
      "Batch: 2, 0.990, 0.990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m start_index\u001b[39m+\u001b[39mchunk_size\u001b[39m>\u001b[39mX_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m     53\u001b[0m     end_index\u001b[39m=\u001b[39mstart_index\u001b[39m+\u001b[39mremainder\n\u001b[0;32m---> 56\u001b[0m y_pred\u001b[39m=\u001b[39mL1_model\u001b[39m.\u001b[39;49mpredict(X_test\u001b[39m.\u001b[39;49miloc[start_index:end_index])\n\u001b[1;32m     57\u001b[0m y_test\u001b[39m=\u001b[39mL1_ytest\u001b[39m.\u001b[39miloc[start_index:end_index]\n\u001b[1;32m     59\u001b[0m acc\u001b[39m=\u001b[39maccuracy_score(y_test,y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:197\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 197\u001b[0m neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[1;32m    198\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m    199\u001b[0m _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/neighbors/_base.py:705\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 705\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(pairwise_distances_chunked(\n\u001b[1;32m    706\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X, reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[1;32m    707\u001b[0m         metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_, n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    708\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    711\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1623\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1622\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 1623\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1624\u001b[0m                              n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1625\u001b[0m \u001b[39mif\u001b[39;00m ((X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1626\u001b[0m         \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(metric, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1627\u001b[0m         \u001b[39mis\u001b[39;00m euclidean_distances):\n\u001b[1;32m   1628\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart::_num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1790\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric,\n\u001b[1;32m   1787\u001b[0m                                                   \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   1788\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1790\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1359\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1356\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1359\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1361\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:313\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    310\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    311\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    314\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    315\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/extmath.py:154\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[0;32m--> 154\u001b[0m \u001b[39mif\u001b[39;00m (sparse\u001b[39m.\u001b[39;49missparse(a) \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    155\u001b[0m         \u001b[39mand\u001b[39;00m dense_output \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m _spbase\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# generate output file\n",
    "for path in [progressLog_path,out_txt_path,out_csv_path]:\n",
    "    if not os.path.isfile(path):\n",
    "        Path(path).touch()\n",
    "\n",
    "\n",
    "# csv writer\n",
    "try:\n",
    "    f=open(progressLog_path,'w')\n",
    "    f.truncate()\n",
    "except:\n",
    "    os.system(\"sudo chmod 777 /home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/L1_progressLog.txt\")\n",
    "    f=open(progressLog_path,'w')\n",
    "    f.truncate()\n",
    "   \n",
    "\n",
    "# save_progress_log\n",
    "def save_progress_log(file_path,batch,accuracy,recall,predictions):\n",
    "    try:\n",
    "        with open(file_path,'a') as file:\n",
    "            result_str=f\"{batch}, {accuracy:.3f}, {recall:.3f}, \"\n",
    "            result_str+=\", \".join(str(pred) for pred in predictions)\n",
    "            file.write(result_str+\"\\n\")\n",
    "    except:\n",
    "        os.system(\"sudo chmod 777 /home/irteam/junghye-dcloud-dir/MLAC/230719/result/CICI/L1_progressLog.txt\")\n",
    "        with open(file_path,'a') as file:\n",
    "            result_str=f\"{batch}, {accuracy:.3f}, {recall:.3f}, \"\n",
    "            result_str+=\", \".join(str(pred) for pred in predictions)\n",
    "            file.write(result_str+\"\\n\")\n",
    "\n",
    "# Define batch size\n",
    "batch_size=1000\n",
    "\n",
    "chunk_size=X_test.shape[0]//batch_size\n",
    "remainder=X_test.shape[0]%batch_size\n",
    "\n",
    "start_index=0\n",
    "end_index=0\n",
    "L1_ypred=[]\n",
    "print('L1 test starts...')\n",
    "\n",
    "print('result is acc, recall, time')\n",
    "\n",
    "for i in range(0,X_test.shape[0],chunk_size):\n",
    "    batch=i//chunk_size+1\n",
    "    start_time=time.time()\n",
    "\n",
    "    # end_index\n",
    "    end_index=start_index+chunk_size\n",
    "\n",
    "    # remainder 처리 \n",
    "    if start_index+chunk_size>X_test.shape[0]:\n",
    "        end_index=start_index+remainder\n",
    "\n",
    "\n",
    "    y_pred=L1_model.predict(X_test.iloc[start_index:end_index])\n",
    "    y_test=L1_ytest.iloc[start_index:end_index]\n",
    "    \n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    recall=recall_score(y_test,y_pred,average='weighted')\n",
    "\n",
    "\n",
    "    \n",
    "    # 중간 결과 저장\n",
    "    print(f\"Batch: {batch}, {acc:.3f}, {recall:.3f}\")\n",
    "    save_progress_log(progressLog_path,batch,acc,recall,y_pred)\n",
    "\n",
    "    # 예측값 합치기\n",
    "    L1_ypred.extend(y_pred)\n",
    "    \n",
    "    # start_index update\n",
    "    start_index=end_index\n",
    "\n",
    "# Layer1 result\n",
    "eval_result=test_result(L1_model,L1_ytest,L1_ypred)\n",
    "model_eval.extend(eval_result)\n",
    "\n",
    "# L1 결과 저장 \n",
    "f=open(progressLog_path,'a')\n",
    "f.write('L1 result'+','.join(map(str,eval_result))+'\\n')\n",
    "f.close()\n",
    "\n",
    "f2=open(out_txt_path,'w')\n",
    "f2.truncate()\n",
    "f2.write(','.join(map(str,L1_ypred)))\n",
    "f2.close()\n",
    "\n",
    "#confusion\n",
    "confusion=metrics.confusion_matrix(L1_ytest,L1_ypred)\n",
    "plot_confusion_matrix(confusion,labels=[0,1],title='Layer1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_indices=np.where(L1_ypred==1)[0]\n",
    "\n",
    "# 최종 결과를 위해 저장\n",
    "L1_b_ypred=[L1_ypred[i] for i in range(len(L1_ypred)) if i not in malicious_indices]\n",
    "L1_b_ytest=[L1_ytest[i] for i in range(len(L1_ytest)) if i not in malicious_indices]\n",
    "\n",
    "\n",
    "if malicious_indices.any():\n",
    "    L2_model=joblib.load(os.path.join(saved_path,'CICI_nist.pkl'))\n",
    "    L2_Xtest=X_test.iloc[malicious_indices]\n",
    "    L2_ypred=L2_model.predict(L2_Xtest)\n",
    "    L2_ytest_selected=L2_ytest.iloc[malicious_indices]\n",
    "    L2_result=test_result(L2_model,L2_ytest_selected,L2_ypred)\n",
    "    \n",
    "    # Layer2 result\n",
    "    f=open(progressLog_path,'a')\n",
    "    f.write('L2 result'+','.join(map(str,L2_result))+'\\n')\n",
    "    f.close()\n",
    "    model_eval.extend(L2_result)\n",
    "else:\n",
    "    print('no malicious predicted')\n",
    "    import sys\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "L2_encoded=[]\n",
    "L2_encoded.extend(L2_ypred)\n",
    "L2_encoded.extend(L2_ytest_selected)\n",
    "L2_encoded=list(set(L2_encoded))\n",
    "\n",
    "confusion=metrics.confusion_matrix(L2_ytest_selected,L2_ypred)\n",
    "plot_confusion_matrix(confusion,labels=L2_encoded,title='Layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class_models = [\n",
    "    joblib.load(os.path.join(saved_path, 'class_1_CICI.pkl')),\n",
    "    joblib.load(os.path.join(saved_path, 'class_2_CICI.pkl')),\n",
    "    joblib.load(os.path.join(saved_path, 'class_3_CICI.pkl')),\n",
    "    joblib.load(os.path.join(saved_path, 'class_4_CICI.pkl'))\n",
    "]\n",
    "\n",
    "class_names = ['Reconnaissance', 'Access', 'Dos', 'Malware']\n",
    "\n",
    "class_encodings=defaultdict(list)\n",
    "final_y_pred=[]\n",
    "final_y_test=[]\n",
    "\n",
    "L3_ytest_selected=L3_ytest.iloc[malicious_indices]\n",
    "\n",
    "for class_index,class_model in enumerate(class_models):\n",
    "    indices=np.where(L2_ypred==class_index+1)[0]\n",
    "    print(class_names[class_index]+'train & test')\n",
    "\n",
    "    if indices.any():\n",
    "        X_test_selected=L2_Xtest.iloc[indices]\n",
    "        y_pred=class_model.predict(X_test_selected)\n",
    "        y_test_selected=L3_ytest_selected.iloc[indices]\n",
    "        result=test_result(class_model,y_test_selected,y_pred)\n",
    "\n",
    "        # 각 classifier result\n",
    "        f=open(progressLog_path,'a')\n",
    "        f.write(str(class_names[class_index])+','.join(map(str,result))+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        model_eval.extend(result)\n",
    "\n",
    "        class_encodings[class_names[class_index]].extend(y_pred)\n",
    "        class_encodings[class_names[class_index]].extend(y_test_selected)\n",
    "\n",
    "        final_y_pred.extend(y_pred)\n",
    "        final_y_test.extend(y_test_selected)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        model_eval.extend([0,0,0,0])\n",
    "\n",
    "\n",
    "final_y_pred.extend(L1_b_ypred)\n",
    "final_y_test.extend(L1_b_ytest)\n",
    "\n",
    "\n",
    "final_result = test_result('Layer3', final_y_test, final_y_pred)\n",
    "\n",
    "# final result\n",
    "f=open(progressLog_path,'a')\n",
    "f.write('final result'+','.join(map(str,final_result))+'\\n')\n",
    "f.close()\n",
    "\n",
    "model_eval.extend(final_result)\n",
    "\n",
    "for class_name in class_names:\n",
    "    confusion = metrics.confusion_matrix(class_encodings[class_name][len(class_encodings[class_name]) // 2:], \n",
    "                                         class_encodings[class_name][:len(class_encodings[class_name]) // 2])\n",
    "    plot_confusion_matrix(confusion,labels=list(set(class_encodings[class_name])),title=class_name)\n",
    "\n",
    "confusion = metrics.confusion_matrix(final_y_test, final_y_pred)\n",
    "plot_confusion_matrix(confusion, labels=list(set(final_y_pred + final_y_test)), title='Layer3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[cnt]=model_eval\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(out_csv_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
