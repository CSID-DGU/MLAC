{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from pipeline import create_pipeline\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# Get Dataset\n",
    "files={\n",
    "    'CICI':'/home/irteam/junghye-dcloud-dir/MLAC/new_data/CICI.csv',\n",
    "    'UNSW':'/home/irteam/junghye-dcloud-dir/MLAC/new_data/UNSW.csv'\n",
    "}\n",
    "\n",
    "data = pd.read_csv(files['CICI'])\n",
    "data=data[np.isfinite(data).all(1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backup=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target\n",
    "binary_t=data['label']\n",
    "multi1_t=data['nist_category']\n",
    "multi2_t=data['attack_category'] # 최종\n",
    "# 마지막 3-class classifier\n",
    "class_1_data=data[data['nist_category']==1] # 여기서 각각 attack_category예측\n",
    "class_2_data=data[data['nist_category']==2]\n",
    "class_3_data=data[data['nist_category']==3]\n",
    "class_4_data=data[data['nist_category']==4]\n",
    "\n",
    "for class_data in [class_1_data,class_2_data,class_3_data,class_4_data]:\n",
    "    class_data.drop(labels=['nist_category','label'],axis=1,inplace=True)\n",
    "\n",
    "data=data.drop(labels=['label','attack_category','nist_category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
    "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
    "models.append(('ABoost', AdaBoostClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['name','b_acc','b_f1','b_rc','b_pc','m_acc','m_f1','m_rc','m_pc']+\\\n",
    "                 ['c1_acc','c1_f1','c1_rc','c1_pc']+\\\n",
    "                    ['c2_acc','c2_f1','c2_rc','c2_pc','c3_acc','c3_f1','c3_rc','c3_pc','c4_acc','c4_f1','c4_rc','c4_pc'])\n",
    "eval_path='/home/irteam/junghye-dcloud-dir/MLAC/evaluation'\n",
    "confusion_path='/home/irteam/junghye-dcloud-dir/MLAC/confusion_matrix/hierarchical'\n",
    "cnt=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data,binary_t,test_size=0.3, shuffle=True, stratify=binary_t, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi1_train=multi1_t.loc[y_train.index]\n",
    "\n",
    "multi1_test=multi1_t.loc[y_test.index]\n",
    "\n",
    "\n",
    "\n",
    "class_1_train=class_1_data.loc[class_1_data.index.isin(y_train.index)] # y값 기준\n",
    "class_1_train_lbl=class_1_train['attack_category']\n",
    "class_1_test_lbl=class_1_data.loc[class_1_data.index.isin(y_test.index),'attack_category']\n",
    "\n",
    "class_2_train=class_2_data.loc[class_2_data.index.isin(y_train.index)]\n",
    "class_2_train_lbl=class_2_train['attack_category']\n",
    "class_2_test_lbl=class_2_data.loc[class_2_data.index.isin(y_test.index),'attack_category']\n",
    "\n",
    "class_3_train=class_3_data.loc[class_3_data.index.isin(y_train.index)]\n",
    "class_3_train_lbl=class_3_train['attack_category']\n",
    "class_3_test_lbl=class_3_data.loc[class_3_data.index.isin(y_test.index),'attack_category']\n",
    "\n",
    "class_4_train=class_4_data.loc[class_4_data.index.isin(y_train.index)]\n",
    "class_4_train_lbl=class_4_train['attack_category']\n",
    "class_4_test_lbl=class_4_data.loc[class_4_data.index.isin(y_test.index),'attack_category']\n",
    "\n",
    "# train data에서 label drop시키기\n",
    "for class_train in [class_1_train,class_2_train, class_3_train,class_4_train]:\n",
    "    class_train.drop(['attack_category'],axis=1,inplace=True)\n",
    "# 각 train이랑 test로 나눔 \n",
    "# 여기서 attack_category가 0인 행들은 빼버리기 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모든 classifier을 동시에 다 train (있는 데이터 다 데리고)\n",
    "    그리고 test할 떄만 계층적으로 내려옴 (test 데이터를 쪼개고쪼개고..??)\n",
    "\n",
    "2. 한 classifier을 train -> train set으로 예측 진행 1로 분류된 데이터 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(model:str,test,pred,target:list) ->list:\n",
    "\n",
    "    acc=accuracy_score(test,pred)\n",
    "    f1=f1_score(test,pred,average='weighted')\n",
    "    recall=recall_score(test,pred,average='weighted')\n",
    "    precision=precision_score(test,pred,average='weighted')\n",
    "    #confusion=metrics.confusion_matrix(test,pred)\n",
    "    #plot_confusion_matrix(confusion,labels=list(set(target)),title=model)\n",
    "    print(f'{model} result , acc:{acc}, f1:{f1},recall:{recall},precision:{precision}')\n",
    "    return([acc,f1,recall,precision])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary train starting...\n",
      "binary test starting...\n",
      "RandomForestClassifier(max_depth=5, max_features=3, n_estimators=5) result , acc:0.9695143803741089, f1:0.9675102441919022,recall:0.9695143803741089,precision:0.9699638505870618\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=3,\n",
      "                                        n_estimators=5))]) result , acc:0.9338648052435171, f1:0.9313830611534732,recall:0.9338648052435171,precision:0.9376436727110034\n",
      "class1 train starting...\n",
      "train 결과: 0.9961868832020466\n",
      "class_1 test starting..\n",
      "RandomForestClassifier(max_depth=5, max_features=3, n_estimators=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class2 train starting...\n",
      "train 결과: 0.7737989263845054\n",
      "class_2 test starting..\n",
      "RandomForestClassifier(max_depth=5, max_features=3, n_estimators=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "RandomForestClassifier(max_depth=5, max_features=3, n_estimators=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "RandomForestClassifier(max_depth=5, max_features=3, n_estimators=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "DecisionTreeClassifier(max_depth=5) result , acc:0.975737324515605, f1:0.9756866031289824,recall:0.975737324515605,precision:0.9756408627179041\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model', DecisionTreeClassifier(max_depth=5))]) result , acc:0.8464399092970522, f1:0.8022935516687806,recall:0.8464399092970522,precision:0.7692248991216323\n",
      "class1 train starting...\n",
      "train 결과: 0.9964216610940649\n",
      "class_1 test starting..\n",
      "DecisionTreeClassifier(max_depth=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class2 train starting...\n",
      "train 결과: 0.7720050713495724\n",
      "class_2 test starting..\n",
      "DecisionTreeClassifier(max_depth=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "DecisionTreeClassifier(max_depth=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "DecisionTreeClassifier(max_depth=5) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "GaussianNB() result , acc:0.8626435136842376, f1:0.8750916472132818,recall:0.8626435136842376,precision:0.8949590175377288\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model', GaussianNB())]) result , acc:0.24071359567990588, f1:0.16417036252094305,recall:0.24071359567990588,precision:0.127154262932091\n",
      "class1 train starting...\n",
      "train 결과: 0.987686304353106\n",
      "class_1 test starting..\n",
      "GaussianNB() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class2 train starting...\n",
      "train 결과: 0.20610450217150872\n",
      "class_2 test starting..\n",
      "GaussianNB() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "GaussianNB() result , acc:0.03258499942100202, f1:0.03796710516660592,recall:0.03258499942100202,precision:0.057601633056162865\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "GaussianNB() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "LinearDiscriminantAnalysis() result , acc:0.9620548916476518, f1:0.961227329126742,recall:0.9620548916476518,precision:0.9608919848577703\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model', LinearDiscriminantAnalysis())]) result , acc:0.8074439822329859, f1:0.7509946989167169,recall:0.8074439822329859,precision:0.7085487435018138\n",
      "class1 train starting...\n",
      "train 결과: 0.9928838011350297\n",
      "class_1 test starting..\n",
      "LinearDiscriminantAnalysis() result , acc:1.879310668846667e-05, f1:2.4690780819969217e-05,recall:1.879310668846667e-05,precision:3.598300996275135e-05\n",
      "class2 train starting...\n",
      "train 결과: 0.7773057106633218\n",
      "class_2 test starting..\n",
      "LinearDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "LinearDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "LinearDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "QuadraticDiscriminantAnalysis() result , acc:0.9701130577148677, f1:0.9709096107592791,recall:0.9701130577148677,precision:0.972538712130043\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model', QuadraticDiscriminantAnalysis())]) result , acc:0.710697767778735, f1:0.6590463331719209,recall:0.710697767778735,precision:0.6306104667733909\n",
      "class1 train starting...\n",
      "train 결과: 0.9930052379757288\n",
      "class_1 test starting..\n",
      "QuadraticDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class2 train starting...\n",
      "train 결과: 0.4123169053977503\n",
      "class_2 test starting..\n",
      "QuadraticDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "QuadraticDiscriminantAnalysis() result , acc:0.0002523641614850229, f1:0.000336379934852395,recall:0.0002523641614850229,precision:0.0005042533590525708\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "QuadraticDiscriminantAnalysis() result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "LogisticRegression(max_iter=200) result , acc:0.9642031171442936, f1:0.9630914596062383,recall:0.9642031171442936,precision:0.9629770285233465\n",
      "multi1 train starting...\n",
      "multi1 test starting...\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('model', LogisticRegression(max_iter=200))]) result , acc:0.832300434742392, f1:0.7877636060897905,recall:0.832300434742392,precision:0.75690056242775\n",
      "class1 train starting...\n",
      "train 결과: 0.9961868832020466\n",
      "class_1 test starting..\n",
      "LogisticRegression(max_iter=200) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class2 train starting...\n",
      "train 결과: 0.7918588654204095\n",
      "class_2 test starting..\n",
      "LogisticRegression(max_iter=200) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class3 train starting...\n",
      "class_3 test starting..\n",
      "LogisticRegression(max_iter=200) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "class4 train starting...\n",
      "class_4 test starting..\n",
      "LogisticRegression(max_iter=200) result , acc:0.0, f1:0.0,recall:0.0,precision:0.0\n",
      "binary train starting...\n",
      "binary test starting...\n",
      "AdaBoostClassifier() result , acc:0.9742491394980083, f1:0.9732516944745687,recall:0.9742491394980083,precision:0.9738764739445981\n",
      "multi1 train starting...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    # all models training (다 같은 trainset으로)\n",
    "    model_eval=[]\n",
    "    model_eval.append(name)\n",
    "    print('binary train starting...')\n",
    "    # binary classification\n",
    "    binary_model=model\n",
    "    \n",
    "    binary_model.fit(X_train,y_train)\n",
    "\n",
    "        # 순차적으로 test 진행\n",
    "    print('binary test starting...')\n",
    "    binary_pred=binary_model.predict(X_test) #  \n",
    "    binary_result=test_result(name,y_test,binary_pred,binary_t)\n",
    "    model_eval.extend(binary_result)\n",
    "    \n",
    "\n",
    "    print('multi1 train starting...')\n",
    "    #2-step training\n",
    "    # 주의 : label이 0인 것 빼고 training\n",
    "    multi1_model=create_pipeline(model)\n",
    "    multi1_model.fit(X_train[multi1_train!=0],multi1_train[multi1_train!=0])\n",
    "    multi1_X_test=X_test.iloc[np.where(binary_pred==1)[0]] # 1로 분류된것만 이게 빈 걸로 반환됨 \n",
    "    \n",
    "    print('multi1 test starting...')\n",
    "    multi1_pred=multi1_model.predict(multi1_X_test)\n",
    "    # 리스트에서 1인 곳 의 값 반환 -> list \n",
    "    multi1_test_selected = multi1_test.iloc[np.where(binary_pred==1)[0]]# label중에서도 1로 분류된 것들만 (1,2,3,4)\n",
    "    multi1_result=test_result(name,multi1_test_selected,multi1_pred,multi1_t)\n",
    "    model_eval.extend(multi1_result)\n",
    "    # last-step training\n",
    "    # all 4 models\n",
    "    \n",
    "    print('class1 train starting...')\n",
    "    class_1_model=model\n",
    "    class_1_model.fit(class_1_train,class_1_train_lbl) # 66개 feature\n",
    "    train_pred=class_1_model.predict(class_1_train)\n",
    "    \n",
    "    print('train 결과:',accuracy_score(class_1_train_lbl,train_pred))\n",
    "    # class_1_test 셋 조정\n",
    "    indices = np.where(multi1_pred == 1)[0]\n",
    "    class_1_test_selected = multi1_X_test.iloc[indices] # 1로 예측된 X_test \n",
    "    \n",
    "     # 이 부분에서 column이 3개 날아가는듯 \n",
    "    print('class_1 test starting..')\n",
    "    class_1_pred=class_1_model.predict(class_1_test_selected) # predict\n",
    "    \n",
    "    class_1_result=test_result(name,multi2_t.iloc[indices],class_1_pred,class_1_test_lbl)\n",
    "    model_eval.extend(class_1_result)\n",
    "    \n",
    "\n",
    "    print('class2 train starting...')\n",
    "    class_2_model=model\n",
    "    class_2_model.fit(class_2_train,class_2_train_lbl)\n",
    "    train_pred=class_2_model.predict(class_2_train)\n",
    "    \n",
    "    print('train 결과:',accuracy_score(class_2_train_lbl,train_pred))\n",
    "    indices2 = np.where(multi1_pred == 2)[0]\n",
    "    class_2_test_selected=multi1_X_test.iloc[indices2]\n",
    "    \n",
    "    print('class_2 test starting..')\n",
    "    class_2_pred=class_2_model.predict(class_2_test_selected)\n",
    "    \n",
    "    class_2_result=test_result(class_2_model,multi2_t.iloc[indices2],class_2_pred,class_2_test_lbl)\n",
    "    model_eval.extend(class_2_result)\n",
    "    \n",
    "\n",
    "    print('class3 train starting...')\n",
    "    class_3_model=model\n",
    "    class_3_model.fit(class_3_train,class_3_train_lbl)\n",
    "    indices3 = np.where(multi1_pred == 3)[0]\n",
    "    class_3_test_selected=multi1_X_test.iloc[indices3]\n",
    "\n",
    "    print('class_3 test starting..')\n",
    "    class_3_pred=class_3_model.predict(class_3_test_selected)\n",
    "    class_3_result=test_result(class_3_model,multi2_t.iloc[indices3],class_3_pred,class_3_test_lbl)\n",
    "\n",
    "    model_eval.extend(class_3_result)\n",
    "\n",
    "\n",
    "    print('class4 train starting...')\n",
    "    class_4_model=model\n",
    "    class_4_model.fit(class_4_train,class_4_train_lbl)\n",
    "    indices4 = np.where(multi1_pred == 4)[0]\n",
    "    class_4_test_selected=multi1_X_test.iloc[indices4]\n",
    "\n",
    "    print('class_4 test starting..')\n",
    "    class_4_pred=class_4_model.predict(class_4_test_selected)\n",
    "    class_4_result=test_result(class_4_model,multi2_t.iloc[indices4],class_4_pred,class_4_test_lbl)\n",
    "\n",
    "    model_eval.extend(class_4_result)\n",
    "   \n",
    "   \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    df.loc[cnt]=model_eval\n",
    "    cnt=cnt+1\n",
    "    \n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(eval_path,'hierarchical.csv'),index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
