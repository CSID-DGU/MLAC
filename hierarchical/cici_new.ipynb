{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from pipeline import create_pipeline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "# Get Dataset\n",
    "files={\n",
    "    'CICI':'/home/irteam/junghye-dcloud-dir/MLAC/data/encoded_ConcatedCICI.csv',\n",
    "    'UNSW': '/home/irteam/junghye-dcloud-dir/MLAC/data/encoded_ConcatedUNSW.csv'\n",
    "}\n",
    "\n",
    "data = pd.read_csv(files['CICI'])\n",
    "data=data[np.isfinite(data).all(1)]\n",
    "multiclass_labels=data['new_category']\n",
    "\n",
    "data=data.drop(labels=['label','attack_category','nist_category','new_category','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
    "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
    "models.append(('ABoost', AdaBoostClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['name','acc','f1_mi','f1_ma','f1_we','recall_mi','recall_ma','recall_we']+\\\n",
    "                 ['precision_mi','precision_ma','precision_we'])\n",
    "eval_path='/home/irteam/junghye-dcloud-dir/MLAC/evaluation'\n",
    "\n",
    "confusion_path='/home/irteam/junghye-dcloud-dir/MLAC/confusion_matrix/new_cici'\n",
    "if os.path.isdir(confusion_path)==False:\n",
    "    os.mkdir(confusion_path)\n",
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data,multiclass_labels,test_size=0.3, shuffle=True, stratify=multiclass_labels, random_state=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot\n",
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee',edgecolor='blue',pad_inches=0.5)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start...RF\n",
      "모델 training 소요 시간: 10.17초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 1.19초\n",
      "name:RF,acc:0.9531017473261598,f1_score:0.9531017473261598,0.4067373195489277,0.947781573471819,recall:0.9531017473261598,0.3991409033727163,0.9531017473261598,precision:0.9531017473261598,0.4166742113606772,0.9460582865338634\n",
      "training start...CART\n",
      "모델 training 소요 시간: 37.05초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 0.90초\n",
      "name:CART,acc:0.96991978093132,f1_score:0.96991978093132,0.512077097067673,0.9660345116530735,recall:0.96991978093132,0.5629781570667648,0.96991978093132,precision:0.96991978093132,0.48519240148534476,0.9624046334326705\n",
      "training start...NB\n",
      "모델 training 소요 시간: 5.23초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 3.42초\n",
      "name:NB,acc:0.7156805021766242,f1_score:0.7156805021766243,0.47965381111271144,0.7806124078380259,recall:0.7156805021766242,0.8143615337086125,0.7156805021766242,precision:0.7156805021766242,0.5376146500345634,0.9061538693860438\n",
      "training start...LDA\n",
      "모델 training 소요 시간: 16.92초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 0.97초\n",
      "name:LDA,acc:0.9561939907557221,f1_score:0.9561939907557221,0.5577511828648041,0.9613057652758963,recall:0.9561939907557221,0.8524413395744093,0.9561939907557221,precision:0.9561939907557221,0.5233663185299273,0.9675439099354574\n",
      "training start...QDA\n",
      "모델 training 소요 시간: 6.35초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 3.89초\n",
      "name:QDA,acc:0.8771308431578898,f1_score:0.8771308431578898,0.43860021707419783,0.8467459296689342,recall:0.8771308431578898,0.6845864658265132,0.8771308431578898,precision:0.8771308431578898,0.37691889532828415,0.8217939557203459\n",
      "training start...LR\n",
      "모델 training 소요 시간: 109.13초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 0.95초\n",
      "name:LR,acc:0.985717884169908,f1_score:0.985717884169908,0.7450685229602577,0.9855452601156263,recall:0.985717884169908,0.7138856390687922,0.985717884169908,precision:0.985717884169908,0.7888506705576627,0.9856785909901389\n",
      "training start...ABoost\n",
      "모델 training 소요 시간: 470.91초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 10.94초\n",
      "name:ABoost,acc:0.8524238027021973,f1_score:0.8524238027021973,0.240408416855683,0.8108187954074486,recall:0.8524238027021973,0.23329961768014038,0.8524238027021973,precision:0.8524238027021973,0.26073632764589016,0.7938071598690971\n",
      "training start...KNN\n",
      "모델 training 소요 시간: 3.46초\n",
      "evaluation start...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    model=create_pipeline(model)\n",
    "    print('training start...'+name)\n",
    "    start_time=time.time()\n",
    "    model.fit(X_train,y_train)\n",
    "    end_time=time.time()\n",
    "    \n",
    "    print(\"모델 training 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    \n",
    "    print('evaluation start...')\n",
    "    start_time=time.time()\n",
    "    y_pred=model.predict(X_test)\n",
    "    end_time=time.time()\n",
    "    print(\"모델 test 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "    #evaluation result\n",
    "    model_eval=[]\n",
    "    model_eval.append(name)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_mi = f1_score(y_test, y_pred,average='micro')\n",
    "    f1_ma = f1_score(y_test, y_pred,average='macro')\n",
    "    f1_we = f1_score(y_test, y_pred,average='weighted')\n",
    "    recall_mi = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_ma = recall_score(y_test, y_pred, average='macro')\n",
    "    recall_we = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision_mi = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_ma = precision_score(y_test, y_pred, average='macro')\n",
    "    precision_we = precision_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    model_eval.append(acc)\n",
    "    model_eval.append(f1_mi)\n",
    "    model_eval.append(f1_ma)\n",
    "    model_eval.append(f1_we)\n",
    "    model_eval.append(recall_mi)\n",
    "    model_eval.append(recall_ma)\n",
    "    model_eval.append(recall_we)\n",
    "    model_eval.append(precision_mi)\n",
    "    model_eval.append(precision_ma)\n",
    "    model_eval.append(precision_we)\n",
    "    \n",
    "    #confusion_metrics\n",
    "    confusion=metrics.confusion_matrix(y_test,y_pred)\n",
    "    plot_confusion_matrix(confusion,labels=['Benign','DoS','Reconnaissance']+\\\n",
    "                          ['Brute Force','Malware','Web Attack','Heartbleed'],title=name)\n",
    "       \n",
    "\n",
    "\n",
    "    print(f'name:{name},acc:{acc},f1_score:{f1_mi},{f1_ma},{f1_we},recall:{recall_mi},{recall_ma},{recall_we},precision:{precision_mi},{precision_ma},{precision_we}')\n",
    "    df.loc[cnt]=model_eval\n",
    "\n",
    "    cnt+=1\n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(eval_path,'new_cici.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
