{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from pipeline import create_pipeline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "# Get Dataset\n",
    "files={\n",
    "    'CICI':'/home/irteam/junghye-dcloud-dir/MLAC/data/encoded_ConcatedCICI.csv',\n",
    "    'UNSW': '/home/irteam/junghye-dcloud-dir/MLAC/data/encoded_ConcatedUNSW.csv'\n",
    "}\n",
    "\n",
    "data = pd.read_csv(files['UNSW'])\n",
    "data=data[np.isfinite(data).all(1)]\n",
    "multiclass_labels=data['new_category']\n",
    "\n",
    "data=data.drop(labels=['label','attack_category','nist_category','new_category','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
    "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
    "models.append(('ABoost', AdaBoostClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['name','acc','f1_mi','f1_ma','f1_we','recall_mi','recall_ma','recall_we']+\\\n",
    "                 ['precision_mi','precision_ma','precision_we'])\n",
    "eval_path='/home/irteam/junghye-dcloud-dir/MLAC/evaluation'\n",
    "confusion_path='/home/irteam/junghye-dcloud-dir/MLAC/confusion_matrix/new_unsw'\n",
    "if os.path.isdir(confusion_path)==False:\n",
    "    os.mkdir(confusion_path)\n",
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data,multiclass_labels,test_size=0.3, shuffle=True, stratify=multiclass_labels, random_state=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot\n",
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee',edgecolor='blue',pad_inches=0.5)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start...RF\n",
      "RF training 소요 시간: 17.33초\n",
      "evaluation start...\n",
      "RF test 소요 시간: 3.50초\n",
      "name:RF,acc:0.8744289074734458,f1_score:0.8744289074734458,0.14288594142862587,0.8164260350820199,recall:0.8744289074734458,0.1478289528140559,0.8744289074734458,precision:0.8744289074734458,0.26563808855911825,0.7813222007306004\n",
      "training start...CART\n",
      "CART training 소요 시간: 43.15초\n",
      "evaluation start...\n",
      "CART test 소요 시간: 3.17초\n",
      "name:CART,acc:0.9686731919306258,f1_score:0.9686731919306258,0.37077743510331057,0.9590547613834819,recall:0.9686731919306258,0.3877869561173693,0.9686731919306258,precision:0.9686731919306258,0.6968599711245977,0.9636611988507532\n",
      "training start...NB\n",
      "NB training 소요 시간: 17.59초\n",
      "evaluation start...\n",
      "NB test 소요 시간: 9.53초\n",
      "name:NB,acc:0.8760542866076412,f1_score:0.8760542866076412,0.19000355402668562,0.8247956260408833,recall:0.8760542866076412,0.19292379793705525,0.8760542866076412,precision:0.8760542866076412,0.37913626955861096,0.7962253744158936\n",
      "training start...LDA\n",
      "LDA training 소요 시간: 60.31초\n",
      "evaluation start...\n",
      "LDA test 소요 시간: 2.86초\n",
      "name:LDA,acc:0.9637996931305304,f1_score:0.9637996931305304,0.537228452615553,0.967811294360814,recall:0.9637996931305304,0.6042181225739007,0.9637996931305304,precision:0.9637996931305304,0.5211083974947907,0.9750774740330028\n",
      "training start...QDA\n",
      "QDA training 소요 시간: 23.89초\n",
      "evaluation start...\n",
      "QDA test 소요 시간: 11.83초\n",
      "name:QDA,acc:0.8512698934136524,f1_score:0.8512698934136524,0.3271587415437862,0.8923059387757171,recall:0.8512698934136524,0.39109728018726997,0.8512698934136524,precision:0.8512698934136524,0.42916163736302476,0.9491434454185796\n",
      "training start...LR\n",
      "LR training 소요 시간: 164.35초\n",
      "evaluation start...\n",
      "LR test 소요 시간: 2.92초\n",
      "name:LR,acc:0.9758145695713722,f1_score:0.9758145695713722,0.5322800279146428,0.9727429573183126,recall:0.9758145695713722,0.5380925977092051,0.9758145695713722,precision:0.9758145695713722,0.575810188684813,0.9729170574786975\n",
      "training start...ABoost\n",
      "ABoost training 소요 시간: 551.27초\n",
      "evaluation start...\n",
      "ABoost test 소요 시간: 22.39초\n",
      "name:ABoost,acc:0.9732300584318522,f1_score:0.9732300584318522,0.5520631187706735,0.9705531799742507,recall:0.9732300584318522,0.5543289209189881,0.9732300584318522,precision:0.9732300584318522,0.6307022903154346,0.9708217254129367\n",
      "training start...KNN\n",
      "KNN training 소요 시간: 11.63초\n",
      "evaluation start...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    model=create_pipeline(model)\n",
    "    print('training start...'+name)\n",
    "    start_time=time.time()\n",
    "    model.fit(X_train,y_train)\n",
    "    end_time=time.time()\n",
    "    \n",
    "    print(name+\" training 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    \n",
    "    print('evaluation start...')\n",
    "    start_time=time.time()\n",
    "    y_pred=model.predict(X_test)\n",
    "    end_time=time.time()\n",
    "    print(name+\" test 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "    #evaluation result\n",
    "    model_eval=[]\n",
    "    model_eval.append(name)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_mi = f1_score(y_test, y_pred,average='micro')\n",
    "    f1_ma = f1_score(y_test, y_pred,average='macro')\n",
    "    f1_we = f1_score(y_test, y_pred,average='weighted')\n",
    "    recall_mi = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_ma = recall_score(y_test, y_pred, average='macro')\n",
    "    recall_we = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision_mi = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_ma = precision_score(y_test, y_pred, average='macro')\n",
    "    precision_we = precision_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    model_eval.append(acc)\n",
    "    model_eval.append(f1_mi)\n",
    "    model_eval.append(f1_ma)\n",
    "    model_eval.append(f1_we)\n",
    "    model_eval.append(recall_mi)\n",
    "    model_eval.append(recall_ma)\n",
    "    model_eval.append(recall_we)\n",
    "    model_eval.append(precision_mi)\n",
    "    model_eval.append(precision_ma)\n",
    "    model_eval.append(precision_we)\n",
    "    \n",
    "    #confusion_metrics\n",
    "    confusion=metrics.confusion_matrix(y_test,y_pred)\n",
    "    plot_confusion_matrix(confusion,labels=['Benign','DoS','Reconnaissance']+\\\n",
    "                          ['Malware','Unauthorized access','Generic','Fuzzers'],title=name)\n",
    "       \n",
    "\n",
    "\n",
    "    print(f'name:{name},acc:{acc},f1_score:{f1_mi},{f1_ma},{f1_we},recall:{recall_mi},{recall_ma},{recall_we},precision:{precision_mi},{precision_ma},{precision_we}')\n",
    "    df.loc[cnt]=model_eval\n",
    "\n",
    "    cnt+=1\n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(eval_path,'new_unsw.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
