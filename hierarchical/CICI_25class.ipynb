{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from pipeline import create_pipeline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# Get Dataset\n",
    "files={\n",
    "    'CICI':'/home/irteam/junghye-dcloud-dir/MLAC/new_data/CICI.csv',\n",
    "    'UNSW':'/home/irteam/junghye-dcloud-dir/MLAC/new_data/UNSW.csv'\n",
    "}\n",
    "\n",
    "data = pd.read_csv(files['CICI'])\n",
    "data=data[np.isfinite(data).all(1)]\n",
    "\n",
    "#multiclass_labels_1=data['nist_category']\n",
    "multiclass_labels_2=data['attack_category']\n",
    "\n",
    "data=data.drop(labels=['label','attack_category','nist_category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
    "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
    "models.append(('ABoost', AdaBoostClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['name','acc','f1_mi','f1_ma','f1_we','rc_mi','rc_ma','rc_we']+\\\n",
    "                 ['pc_mi','pc_ma','pc_we'])\n",
    "eval_path='/home/irteam/junghye-dcloud-dir/MLAC/evaluation'\n",
    "confusion_path='/home/irteam/junghye-dcloud-dir/MLAC/confusion_matrix/CICI_16class'\n",
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data,multiclass_labels_2,test_size=0.3, shuffle=True, stratify=multiclass_labels_2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot\n",
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee',edgecolor='blue')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start..RF\n",
      "evalutaion start..\n",
      "name:RF,acc:0.9465881011214597,f1_score:0.9465881011214597,0.3123132167235964,0.9367214753346027,recall:0.9465881011214597,0.2930530809082538,0.9465881011214597,precision:0.9465881011214597,0.35026745914887314,0.9363931593572624\n",
      "training start..CART\n",
      "evalutaion start..\n",
      "name:CART,acc:0.982206851150435,f1_score:0.982206851150435,0.40141846652709007,0.976867589701638,recall:0.982206851150435,0.37145816461098874,0.982206851150435,precision:0.982206851150435,0.5649154220323831,0.9747664827779271\n",
      "training start..NB\n",
      "evalutaion start..\n",
      "name:NB,acc:0.7823978562918114,f1_score:0.7823978562918114,0.5034931857091386,0.8413174854255229,recall:0.7823978562918114,0.8907669264470603,0.7823978562918114,precision:0.7823978562918114,0.47729111019756215,0.934752280643054\n",
      "training start..LDA\n",
      "evalutaion start..\n",
      "name:LDA,acc:0.9461600394373075,f1_score:0.9461600394373075,0.4774904168787731,0.9534724135036096,recall:0.9461600394373075,0.6992959019101015,0.9461600394373075,precision:0.9461600394373075,0.43776832284004435,0.9623195938249214\n",
      "training start..QDA\n",
      "evalutaion start..\n",
      "name:QDA,acc:0.9751863304605295,f1_score:0.9751863304605295,0.6769696961143599,0.9790430977253864,recall:0.9751863304605295,0.7799391263337571,0.9751863304605295,precision:0.9751863304605295,0.6588524818105571,0.9843347368944438\n",
      "training start..LR\n",
      "evalutaion start..\n",
      "name:LR,acc:0.9895395323464734,f1_score:0.9895395323464734,0.6805560232917695,0.9890822841622595,recall:0.9895395323464734,0.657406808696505,0.9895395323464734,precision:0.9895395323464734,0.7211126204333441,0.9891556060069691\n",
      "training start..ABoost\n",
      "evalutaion start..\n",
      "name:ABoost,acc:0.8121489160149157,f1_score:0.8121489160149157,0.1117345025575667,0.7443110092086688,recall:0.8121489160149157,0.1192177770373053,0.8121489160149157,precision:0.8121489160149157,0.15579153889359723,0.729296761751992\n",
      "training start..KNN\n",
      "evalutaion start..\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    #data_loader()\n",
    "    # binary classification\n",
    "    model=create_pipeline(model)\n",
    "   \n",
    "    print(\"training start..\"+name)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    #evaluation\n",
    "    print('evalutaion start..')\n",
    "    y_pred=model.predict(X_test)\n",
    "    #evaluation result\n",
    "    model_eval=[]\n",
    "    model_eval.append(name)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_mi = f1_score(y_test, y_pred,average='micro')\n",
    "    f1_ma = f1_score(y_test, y_pred,average='macro')\n",
    "    f1_we = f1_score(y_test, y_pred,average='weighted')\n",
    "    recall_mi = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_ma = recall_score(y_test, y_pred, average='macro')\n",
    "    recall_we = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision_mi = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_ma = precision_score(y_test, y_pred, average='macro')\n",
    "    precision_we = precision_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "\n",
    "    model_eval.extend([acc,f1_mi,f1_ma,f1_we,recall_mi,recall_ma,recall_we,precision_mi,precision_ma,precision_we])\n",
    "    \n",
    "    #confusion_metrics\n",
    "    confusion=metrics.confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    plot_confusion_matrix(confusion,labels=['Benign','Analysis', 'Backdoor', 'Bot', 'DDoS', 'DoS', 'DoS GoldenEye', 'DoS Slowhttptest', 'DoS slowloris', 'Dos Hulk', 'Exploits', 'FTP-Patator', 'Fuzzers', 'Generic', 'Heartbleed', 'Infiltration']+\\\n",
    "                                             ['PortScan', 'Reconnaissance', 'SSH-Patator', 'Shellcode', 'Web Attack – Brute Force', 'Web Attack – Sql Injection', 'Web Attack – XSS', 'Worms'],title=name)\n",
    "       \n",
    "\n",
    "\n",
    "    print(f'name:{name},acc:{acc},f1_score:{f1_mi},{f1_ma},{f1_we},recall:{recall_mi},{recall_ma},{recall_we},precision:{precision_mi},{precision_ma},{precision_we}')\n",
    "    df.loc[cnt]=model_eval\n",
    "\n",
    "    cnt+=1\n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(eval_path,'CICI_25class.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#파일명\n",
    "img_files=os.listdir(confusion_path)\n",
    "\n",
    "images=[] # 이미지 리스트\n",
    "for img_file in img_files:\n",
    "    img=Image.open(img_file)\n",
    "    img.resize((400,300))\n",
    "    images.append(img)\n",
    "\n",
    "# 크기\n",
    "width,height=images[0].size\n",
    "new_width=width*3\n",
    "new_height=height*3\n",
    "new_img=Image.new('RGB',(new_width,new_height))\n",
    "\n",
    "#이미지 합치기\n",
    "x_offset=0\n",
    "y_offset=0\n",
    "for img in images:\n",
    "    new_img.paste(img,(x_offset,y_offset))\n",
    "    x_offset+=width\n",
    "    if x_offset==new_width:\n",
    "        x_offset=0\n",
    "        y_offset+=height\n",
    "\n",
    "\n",
    "new_img.save(confusion_path+'merged_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
